---
---
# pdf={percom_paper.pdf},
 $ altmetric={248277},
  #dimensions={true},
  #google_scholar_id={4313511207264604263},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},





@INPROCEEDINGS{PPO-LSTM,
  abstract={Underground mining is a hazardous environment, with frequent accidents leading to significant loss of life each year. To enhance safety, sensor nodes monitor key environmental factors such as temperature, toxic gases, and miners' locations, as well as transmit critical messages. Miners interact with these sensors, which track their movements, enabling their location to be determined even without GPS signals. Therefore, predicting the battery life of these sensors is essential for: (i) rerouting miners during emergencies, (ii) ensuring timely maintenance, and most importantly (iii) identifying sensors that need energy harvesting to maintain vital communication within the mine. In this work, we propose a deep reinforcement learning (DRL) approach, Proximal Policy Optimization-Long Short-Term Memory (PPO-LSTM), specifically tailored for the mining environment. This approach considers miners' movements and communication dynamics to predict sensor battery levels, facilitating timely "energy harvesting" for sensors nearing depletion at critical locations within the mine. Our PPO-LSTM framework integrates LSTM networks with PPO to leverage temporal data correlations, enabling better decision-making for energy management.  Our extensive simulations demonstrate that the PPO-LSTM framework significantly outperforms current state-of-the-art methods, including Deep Deterministic Policy Gradient (DDPG) and  Soft Actor-Critic (SAC). Specifically, it achieves improvements of approximately 4%, 1.07%, and 5-10% in Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE), respectively.},
  bibtex_show={true},
  abbr={SAC'25},
  preview={PPO-LSTM.png},
  author={Anand Yadav, Manish and Elmahallawy, Mohamed and Madria, Sanjay and and Frimpong, Samuel},
  booktitl={The 40th ACM/SIGAPP Symposium On Applied Computing (SAC 2025)},
  title={Predicting Battery Levels of Sensor Nodes Using Reinforcement Learning in Harsh Underground Mining Environments}, 
  year={2024},
  volume={},
  number={},
  pdf= PPOLSTM.pdf,
  pages={},
  keywords={Wireless sensor networks, underground mines, reinforcement learning, actor-critic methods, proximal policy optimization},
  doi={},
  url={},
  html={},
  selected={true}
  }


@INPROCEEDINGS{SKAD,
  abstract={Detecting disasters in underground mining, such as explosions and structural damage, has been a persistent challenge over the years. This problem is compounded for first responders, who often have no clear information about the extent or nature of the damage within the mine. The poor light or even total darkness inside the mines makes rescue efforts incredibly difficult, leading to a tragic loss of life. In this paper, we propose a novel instance segmentation method called DIS-Mine, specifically designed to identify disaster-affected areas within underground mines under low-light or poor visibility conditions, aiding first responders in rescue efforts. DIS-Mine is capable of detecting objects in images, even in complete darkness, by addressing challenges such as high noise, color distortions, and reduced contrast. The key innovations of DIS-Mine are built upon four core components: i) Image brightness improvement, ii) Instance segmentation with segment anything model (SAM) integration, iii) Mask R-CNN-based segmentation, and iv) Mask alignment with feature matching.  On top of that, we have collected real-world images from an experimental underground mine, introducing a new dataset named ImageMine,  specifically gathered in low-visibility conditions. This dataset serves to validate the performance of DIS-Mine in realistic, challenging environments. Our comprehensive experiments on the ImageMine dataset, as well as on various other datasets demonstrate that DIS-Mine achieves a superior F1 score of 86% and mIoU of 72%, outperforming state-of-the-art instance segmentation methods, with at least 15x improvement and up to 80% higher precision in object detection.},
  bibtex_show={true},
  abbr={BigData'24},
  preview={SKAD.png},
  author={Mustafa, Yasmine and Elmahallawy, Mohamed and Luo, Tie},
  booktitl={2024 IEEE International Conference on Big Data (Big Data)},
  title={Efficient Brain Imaging Analysis for Alzheimer's and Dementia Detection Using Convolution-Derivative Operations}, 
  year={2024},
  volume={},
  number={},
  pdf= SKAD.pdf,
  pages={},
  keywords={Medical imaging, Alzheimer's disease, dementia, Jacobian maps, Sobel kernel angle difference (SKAD), voxel-based morphometry (VBM)},
  doi={},
  url={https://arxiv.org/pdf/2411.13490},
  html={https://arxiv.org/pdf/2411.13490},
  selected={true}
  }




@INPROCEEDINGS{DISMine,
  abstract={Detecting disasters in underground mining, such as explosions and structural damage, has been a persistent challenge over the years. This problem is compounded for first responders, who often have no clear information about the extent or nature of the damage within the mine. The poor light or even total darkness inside the mines makes rescue efforts incredibly difficult, leading to a tragic loss of life. In this paper, we propose a novel instance segmentation method called DIS-Mine, specifically designed to identify disaster-affected areas within underground mines under low-light or poor visibility conditions, aiding first responders in rescue efforts. DIS-Mine is capable of detecting objects in images, even in complete darkness, by addressing challenges such as high noise, color distortions, and reduced contrast. The key innovations of DIS-Mine are built upon four core components: i) Image brightness improvement, ii) Instance segmentation with segment anything model (SAM) integration, iii) Mask R-CNN-based segmentation, and iv) Mask alignment with feature matching.  On top of that, we have collected real-world images from an experimental underground mine, introducing a new dataset named ImageMine,  specifically gathered in low-visibility conditions. This dataset serves to validate the performance of DIS-Mine in realistic, challenging environments. Our comprehensive experiments on the ImageMine dataset, as well as on various other datasets demonstrate that DIS-Mine achieves a superior F1 score of 86% and mIoU of 72%, outperforming state-of-the-art instance segmentation methods, with at least 15x improvement and up to 80% higher precision in object detection.},
  bibtex_show={true},
  abbr={BigData'24},
  preview={DISMine.png},
  author={Mizanur Rahman, Jewel and Elmahallawy, Mohamed and Madria, Sanjay and Frimpong, Samuel},
  booktitl={2024 IEEE International Conference on Big Data (Big Data)},
  title={DIS-Mine: Instance Segmentation for Disaster-Awareness in Poor-Light Condition in Underground Mine}, 
  year={2024},
  volume={},
  number={},
  pdf= DISMine.pdf,
  pages={},
  keywords={Disaster detection, underground mining, instance segmentation, image enhancement, automatic annotation},
  doi={},
  url={https://arxiv.org/pdf/2411.13544},
  html={https://arxiv.org/pdf/2411.13544},
  selected={true}
  }




@INPROCEEDINGS{FisherMask,
  abstract={Deep learning (DL) models are popular across various domains due to their remarkable performance and efficiency. However, their effectiveness relies heavily on large amounts of labeled data, which are often time-consuming and labor-intensive to generate manually. To overcome this challenge, it is essential to develop strategies that reduce reliance on extensive labeled data while preserving model performance. In this paper, we propose FisherMask, a Fisher information-based active learning (AL) approach that identifies key network parameters by masking them based on their Fisher information values. FisherMask enhances batch AL by using Fisher information to select the most critical parameters, allowing the identification of the most impactful samples during AL training. Moreover, Fisher information possesses favorable statistical properties, offering valuable insights into model behavior and providing a better understanding of the performance characteristics within the AL pipeline. Our extensive experiments demonstrate that FisherMask significantly outperforms state-of-the-art methods on diverse datasets, including CIFAR-10 and FashionMNIST, especially under imbalanced settings. These improvements lead to substantial gains in labeling efficiency. Hence serving as an effective tool to measure the sensitivity of model parameters to data samples.},
  bibtex_show={true},
  abbr={BigData'24},
  preview={Fishermask.png},
  author={Gul, Shreen and Elmahallawy, Mohamed and Madria, Sanjay and Tripathy, Ardhendu },
  booktitl={2024 IEEE International Conference on Big Data (Big Data)},
  title={FisherMask: Enhancing Neural Network Labeling Efficiency in Image Classification Using Fisher Information}, 
  year={2024},
  volume={},
  number={},
  pdf= Fishermask.pdf,
  pages={},
  keywords={Data labeling, active learning, information matrix, Fisher information},
  doi={},
  url={https://arxiv.org/pdf/2411.05752},
  html={https://arxiv.org/pdf/2411.05752},
  selected={true}
  }


  @INPROCEEDINGS{LPLgrad,
  abstract={Machine learning models are increasingly being utilized across various fields and tasks due to their outstanding performance and strong generalization capabilities. However, these models require substantial amounts of annotated input data, which is labor-intensive, time-consuming, and costly to obtain. Many active learning (AL) approaches have been proposed to address these challenges, but they often fail to fully leverage the information from the core phases of AL, such as training on the labeled set and querying new unlabeled samples. To address this gap, we propose a novel AL approach named Loss Prediction Loss with Gradient Norm (LPLgrad) to quantify model uncertainty and enhance the accuracy of image classification. LPLgrad comprises two phases:(i) Training Phase to predict the loss for the input features by training a main model alongside an auxiliary model. Both models are trained jointly on the labeled input data, maximizing the efficiency of the training phase—an often neglected aspect in previous AL methods. This dual-model approach facilitates the extraction of complex input features and the learning of intrinsic patterns; (ii) Querying Phase to quantify the uncertainty of the main model to select samples accordingly by calculating the gradient norm of the entropy values of samples in the unlabeled set. Samples with the highest gradient norms are selected for labeling and added to the labeled set. Extensive evaluations on real-world datasets demonstrate that the LPLgrad approach outperforms state-of-the-art methods by order of magnitude in terms of accuracy on a small number of labeled images, yet achieving comparable training and querying times in multiple image classification tasks.},
  bibtex_show={true},
  abbr={BigData'24},
  preview={LPLgrad.png},
  author={ Gul, Shreen and Elmahallawy, Mohamed and Madria, Sanjay and Tripathy, Ardhendu },
  booktitle={2024 IEEE International Conference on Big Data (Big Data)},
  title={LPLgrad: Optimizing Active Learning Through Gradient Norm Sample Selection and Auxiliary Model Training}, 
  year={2024},
  volume={},
  number={},
  pdf= LPLgrad.pdf,
  pages={},
  keywords={Active learning, image classification, uncertainty quantification, loss prediction},
  doi={},
  url={https://arxiv.org/pdf/2411.15217},
  html={https://arxiv.org/pdf/2411.15217},
  selected={true}
  }
  

@INPROCEEDINGS{MASS_202,
  abstract={The adoption of connected and automated vehicles (CAVs) has sparked considerable interest across diverse industries, including public transportation, underground mining, and agriculture sectors. However, CAVs' reliance on sensor readings makes them vulnerable to significant threats. Manipulating these readings can compromise CAV network security, posing serious risks for malicious activities. Although several anomaly detection (AD) approaches for CAV networks are proposed, they often fail to: i) detect multiple anomalies in specific sensor(s) with high accuracy or F1 score, and ii) identify the specific sensor being attacked. In response, this paper proposes a novel framework tailored to CAV networks, called CAV-AD, for distinguishing abnormal readings amidst multiple anomaly data while identifying malicious sensors. Specifically, CAV-AD comprises two main components: i) A novel CNN model architecture called optimized omni-scale CNN (O-OS-CNN), which optimally selects the time scale by generating all possible kernel sizes for input time series data; ii) An amplification block to increase the values of anomaly readings, enhancing sensitivity for detecting anomalies. Not only that, but CAV-AD integrates the proposed O-OS-CNN with a Kalman filter to instantly identify the malicious sensors. We extensively train CAV-AD using real-world datasets containing both instant and constant attacks, evaluating its performance in detecting intrusions from multiple anomalies, which presents a more challenging scenario. Our results demonstrate that CAV-AD outperforms state-of-the-art methods, achieving an average accuracy of 98% and an average F1 score of 89%, while accurately identifying the malicious sensors.},
  bibtex_show={true},
  abbr={MASS'24},
  preview={MASS_img.png},
  author={Rahman, Md Sazedur and Elmahallawy, Mohamed and Madria, Sanjay and Frimpong, Samuel},
  booktitle={2024 IEEE International Conference on Mobile Ad-Hoc and Smart Systems (MASS)}, 
  title={CAV-AD: A Robust Framework for Detection of Anomalous Data and Malicious Sensors in CAV Networks},
  year={2024},
  volume={},
  number={},
  pdf= IEEE_MASS.pdf,
  pages={80-89},
  keywords={Anomaly detection; autonomous vehicles;  connected vehicles; sensors data},
  url={https://arxiv.org/abs/2407.05461},
  html={https://ieeexplore.ieee.org/abstract/document/10723487},
  selected={true}
  }
}
@INPROCEEDINGS{10494442,
  abstract={In the ambitious realm of space AI, the integration of federated learning (FL) with low Earth orbit (LEO) satellite constellations holds immense promise. However, many challenges persist in terms of feasibility, learning efficiency, and convergence. These hurdles stem from the bottleneck in communication, characterized by sporadic and irregular connectivity between LEO satellites and ground stations, coupled with the limited computation capability of satellite edge computing (SEC). This paper proposes a novel FL-SEC framework that empowers LEO satellites to execute large-scale machine learning (ML) tasks onboard efficiently. Its key components include i) personalized learning via divide-and-conquer, which identifies and eliminates redundant satellite images and converts complex multi-class classification problems to simple binary classification, enabling rapid and energy-efficient training of lightweight ML models suitable for IoT/edge devices on satellites; ii) orbital model retraining, which generates an aggregated “orbital model” per orbit and retrains it before sending to the ground station, significantly reducing the required communication rounds. We conducted experiments using Jetson Nano, an edge device closely mimicking the limited compute on LEO satellites, and a real satellite dataset. The results underscore the effectiveness of our approach, highlighting SEC's ability to run lightweight ML models on real and high-resolution satellite imagery. Our approach dramatically reduces FL convergence time by nearly 30 times, and satellite energy consumption down to as low as 1.38 watts, all while maintaining an exceptional accuracy of up to 96%. },
  bibtex_show={true},
  abbr={PerCom'24},
  preview={_img.png},
  author={Elmahallawy, Mohamed and Luo, Tie},
  booktitle={2024 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={Stitching Satellites to the Edge: Pervasive and Efficient Federated LEO Satellite Learning}, 
  year={2024},
  volume={},
  number={},
  pdf= PERCOM_PAPER_FINAL.pdf,
  pages={80-89},
  keywords={Training;Space vehicles;Energy consumption;Satellites;Computational modeling;Image edge detection;Low earth orbit satellites;Low Earth orbit (LEO) satellite;satellite edge computing (SEC);federated Learning (FL)},
  doi={10.1109/PerCom59722.2024.10494442},
  url={https://ieeexplore.ieee.org/abstract/document/10494442},
  html={https://ieeexplore.ieee.org/abstract/document/10494442},
  selected={true}
  }
  
  @ARTICLE{10438925,
  abstract={Space AI has become increasingly important and sometimes even necessary for government, businesses, and society. An active research topic under this mission is integrating federated learning (FL) with satellite communications (SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively train a machine learning model. However, the special communication environment of SatCom leads to a very slow FL training process up to days and weeks. This paper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO satellites, that (1) utilizes high-altitude platforms (HAPs) as distributed parameter servers ( PSs ) to enhance satellite visibility, and (2) introduces non-orthogonal multiple access (NOMA) into LEO to enable fast and bandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a new communication topology that exploits HAPs to bridge satellites among different orbits to mitigate the Doppler shift, and (4) a new FL model aggregation scheme that optimally balances models between different orbits and shells. Moreover, we (5) derive a closed-form expression of the outage probability for satellites in near and far shells, as well as for the entire system. Our extensive simulations have validated the mathematical analysis and demonstrated the superior performance of NomaFedHAP in achieving fast and efficient FL model convergence with high accuracy as compared to the state-of-the-art.},
  bibtex_show={true},
  abbr={JSAC'24},
  preview={JSAC.png},
  author={Elmahallawy, Mohamed and Luo, Tie and Ramadan, Khaled},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Communication-Efficient Federated Learning for LEO Constellations Integrated With HAPs Using Hybrid NOMA-OFDM}, 
  year={2024},
  volume={42},
  number={5},
  pages={1097-1114},
  keywords={Satellites;Low earth orbit satellites;Satellite broadcasting;Convergence;Training;Earth;NOMA;Low Earth orbit (LEO);federated learning;high altitude platform (HAP);non-orthogonal multiple access (NOMA)},
  doi={10.1109/JSAC.2024.3365885},
  pdf=Communication-Efficient_paper.pdf,
  url={https://ieeexplore.ieee.org/abstract/document/10438925},
  html={https://ieeexplore.ieee.org/abstract/document/10438925}, 
  selected={true}
  }




@ARTICLE{9944663,
  abstract={According to the United States environmental protection agency (EPA), every burned gallon of gasoline generates 8.87 Kg of CO2. The pollution created by vehicles’ fuel consumption has been one of the primary sources of environmental contamination that can lead to more climate changes and global warming. Thus, science and technology have converged on the idea that reducing fuel consumption benefits the environment and human health. One of the ideas for reducing fuel usage is deploying hybrid electric vehicles (HEVs) and electric vehicles (EVs) using renewable energy as alternatives to gasoline. One of the main issues with EV batteries is that over operational time the battery health degrades and ultimately becomes unsafe to use. It is crucial that safety issues be addressed by researchers and battery manufacturers. Assessing and predicting battery health has been a high-priority research topic to attempt to mitigate the danger introduced by EV batteries. Although various techniques have been developed to estimate and predict the battery’s state of health (SOH), they do not cover all degradation scenarios that may affect the battery’s lifetime. In addition, the models used in estimating and predicting the battery’s lifetime need to be improved to provide a more accurate battery health state and guarantee battery safety while in use by an EV. Even though all types of EV batteries face similar issues, this paper focuses on Li-ion EV batteries. The main objectives of this paper are 1) to present various Li-ion battery models that are used to mimic battery dynamic behaviors, 2) to discuss the degradation factors that cause the battery lifespan to be degraded, and to become unsafe, 3) to provide a review of the estimation and prediction techniques used for Li-ion battery SOH and remaining useful life (RUL) estimation along with a discussion of their advantages and limitations, and 4) to provide recommendations for improving Li-ion battery lifetime estimation. This paper represents a concise source of information for battery community researchers to help expedite beneficial and practical outcomes to improve EV battery safety.},
  bibtex_show={true},
  title={A Comprehensive Review of Lithium-Ion Batteries Modeling, and State of Health and Remaining Useful Lifetime Prediction}, 
  author={Elmahallawy, Mohamed and Elfouly, Tarek and Alouani, Ali and Massoud, Ahmed M.},
  year={2022},
  abbr={IEE Access'22},
  journal={IEEE Access}, 
  preview={EV_paper.png},
  volume={10},
  pages={119040-119070},
  doi={10.1109/ACCESS.2022.3221137},
  pdf=Lithium-Ion_Batteries_paper.pdf,
  url={https://ieeexplore.ieee.org/abstract/document/9944663},
  html={https://ieeexplore.ieee.org/abstract/document/9944663},
  altmetric={248277}
  }

  @INPROCEEDINGS{10039157,
  abstract={Low Earth Orbit (LEO) satellite constellations have seen a surge in deployment over the past few years by virtue of their ability to provide broadband Internet access as well as to collect vast amounts of Earth observational data that can be utilized to develop AI on a global scale. As traditional machine learning (ML) approaches that train a model by downloading satellite data to a ground station (GS) are not practical, Federated Learning (FL) offers a potential solution. However, existing FL approaches cannot be readily applied because of their excessively prolonged training time caused by the challenging satellite-GS communication environment. This paper proposes FedHAP, which introduces high-altitude platforms (HAPs) as distributed parameter servers (PSs) into FL for Satcom (or more concretely LEO constellations), to achieve fast and efficient model training. FedHAP consists of three components: 1) a hierarchical communication architecture, 2) a model dissemination algorithm, and 3) a model aggregation algorithm. Our extensive simulations demonstrate that FedHAP significantly accelerates FL model convergence as compared to state-of-the-art baselines, cutting the training time from several days down to a few hours, yet achieving higher accuracy.},
  bibtex_show={true},
  abbr={WCSP'22},
   preview={FedHap.png},
  author={Elmahallawy, Mohamed and Luo, Tie},
  booktitle={2022 14th International Conference on Wireless Communications and Signal Processing (WCSP)}, 
  title={FedHAP: Fast Federated Learning for LEO Constellations using Collaborative HAPs}, 
  year={2022},
  volume={},
  number={},
  pages={888-893},
  doi={10.1109/WCSP55476.2022.10039157},
  pdf=FedHAP_paper.pdf,
  url={https://ieeexplore.ieee.org/abstract/document/10039157},
  html={https://ieeexplore.ieee.org/abstract/document/10039157},
  }
  

  @INPROCEEDINGS{10021101,
  abstract={Low Earth Orbit (LEO) constellations, each comprising a large number of satellites, have become a new source of big data "from the sky". Downloading such data to a ground station (GS) for big data analytics demands very high bandwidth and involves large propagation delays. Federated Learning (FL) offers a promising solution because it allows data to stay in-situ (never leaving satellites) and it only needs to transmit machine learning model parameters (trained on the satellites’ data). However, the conventional, synchronous FL process can take several days to train a single FL model in the context of satellite communication (Satcom), due to a bottleneck caused by straggler satellites. In this paper, we propose an asynchronous FL framework for LEO constellations called AsyncFLEO to improve FL efficiency in Satcom. Not only does AsynFLEO address the bottleneck (idle waiting) in synchronous FL, but it also solves the issue of model staleness caused by straggler satellites. AsyncFLEO utilizes high altitude platforms (HAPs) positioned "in the sky" as parameter servers, and consists of three technical components: (1) a ring-of-stars communication topology, (2) a model propagation algorithm, and (3) a model aggregation algorithm with satellite grouping and staleness discounting. Our extensive evaluation with both IID and non-IID data shows that AsyncFLEO outperforms the state of the art by a large margin, cutting down convergence delay by 22 times and increasing accuracy by 40%.},
  bibtex_show={true},
  abbr={BigData'22},
  preview={AsyncFLEO.png},
  author={Elmahallawy, Mohamed and Luo, Tie},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={AsyncFLEO: Asynchronous Federated Learning for LEO Satellite Constellations with High-Altitude Platforms}, 
  year={2022},
  volume={},
  number={},
  pages={5478-5487},
  doi={10.1109/BigData55660.2022.10021101},
  pdf=BigData_paper.pdf,
  url={https://ieeexplore.ieee.org/abstract/document/10021101},
  html={https://ieeexplore.ieee.org/abstract/document/10021101},
  }

  @INPROCEEDINGS{10279316,
  abstract={The advances in satellite technology developments have recently seen a large number of small satellites being launched into space on Low Earth orbit (LEO) to collect massive data such as Earth observational imagery. The traditional way which downloads such data to a ground station (GS) to train a machine learning (ML) model is not desirable due to the bandwidth limitation and intermittent connectivity between LEO satellites and the GS. Satellite edge computing (SEC), on the other hand, allows each satellite to train an ML model onboard and uploads only the model to the GS which appears to be a promising concept. This paper proposes FedLEO, a novel federated learning (FL) framework that realizes the concept of SEC and overcomes the limitation (slow convergence) of existing FL-based solutions. FedLEO (1) augments the conventional FL's star topology with “horizontal” intra-plane communication pathways in which model propagation among satellites takes place; (2) optimally schedules communication between “sink” satellites and the GS by exploiting the predictability of satellite orbiting patterns. We evaluate FedLEO extensively and benchmark it with the state of the art. Our results show that FedLEO drastically expedites FL convergence, without sacrificing-in fact it considerably increases-the model accuracy.},
  bibtex_show={true},
  abbr={ICC'23},
  preview={FedLEO.png},
  author={Elmahallawy, Mohamed and Luo, Tie},
  booktitle={ICC 2023 - IEEE International Conference on Communications}, 
  title={Optimizing Federated Learning in LEO Satellite Constellations via Intra-Plane Model Propagation and Sink Satellite Scheduling}, 
  year={2023},
  volume={},
  number={},
  pages={3444-3449},
  keywords={Satellite constellations;Satellites;Federated learning;Computational modeling;Low earth orbit satellites;Stars;Benchmark testing},
  doi={10.1109/ICC45041.2023.10279316},
  pdf=FedLEO_Paper.pdf,
  url={https://ieeexplore.ieee.org/abstract/document/10279316},
  html={https://ieeexplore.ieee.org/abstract/document/10279316}, 
  
  }

  @article{el2019performance,
  abstract={The supported bandwidth of the underwater communication systems is limited to several kilo hertz, which considers as the main challenge for Underwater Acoustic (UWA) communications. Meanwhile, the Bit-Error-Rate (BER) performance of the UWA systems is degrades as a result of water temperature, water salinity, attenuation, and multi-path propagation. In this paper, we present a modification to the conventional Orthogonal Frequency Division Multiplexing (OFDM) based (FFT) using Fast Walsh–Hadamard transform (FWHT) instead of Fast Fourier Transform (FFT). Also, the proposed algorithm is encoded and decoded using Low Density Parity Check (LDPC) coding algorithm. Simulation results show that the proposed algorithm with LDPC coding can improve the BBER system performance than the corresponding traditional one.},
  bibtex_show={true},
  abbr={WPC'19},
  preview={WPC.png},
  title={Performance enhancement of underwater acoustic OFDM communication systems},
  author={El-Mahallawy, Mohamed and TagEldien, Adly S and Elagooz, Salah S},
  journal={Wireless Personal Communications},
  volume={108},
  pages={2047--2057},
  year={2019},
  publisher={Springer},
  pdf=WPC_PAPER.pdf,
  url={https://link.springer.com/article/10.1007/s11277-019-06508-6},
  html={https://link.springer.com/article/10.1007/s11277-019-06508-6}, 
}

@article{el2019performance,
  abstract={The available bandwidth of underwater environment tends to several kilohertz, which considers the main challenges of communications under sea water. On the other hand, the bit-error-rate (BER) performance degrades because of several reasons such as multipath propagation, time variabilities of the channel, attenuation, and water temperature. In this paper, we aim to improve the underwater acoustic (UWA) BER system performance by using orthogonal frequency division multiplexing (OFDM) based on fast Walsh-Hadamard transform (FWHT) instead off fast Fourier transform (FFT). We proposed a low-complexity equalization and carrier frequency offset (CFO) compensation for UWA-OFDM–based FWHT using banded-matrix approximation concept. Simulation results show that the UWA-OFDM–based FWHT with low-density parity check (LDPC) codes give a good improvement performance compared with traditional OFDM in UWA system especially in case of estimation errors.},
  bibtex_show={true},
  abbr={IJCS'19},
  preview={IJCS.png},
  title={Performance enhancement of UWA-OFDM communication systems based on FWHT},
  author={El-Mahallawy, Mohamed and Eldien, Adly Tag},
  journal={International Journal of Communication Systems},
  volume={32},
  number={16},
  pages={e3979},
  year={2019},
  publisher={Wiley Online Library},
  pdf=IJCS_PAPER.pdf,
  url={https://onlinelibrary.wiley.com/doi/full/10.1002/dac.3979},
  html={https://onlinelibrary.wiley.com/doi/full/10.1002/dac.3979}, 

}

@INPROCEEDINGS{10214895,
  abstract={A Low Earth orbit (LEO) satellite constellation consists of a large number of small satellites traveling in space with high mobility and collecting vast amounts of mobility data such as cloud movement for weather forecast, large herds of animals migrating across geo-regions, spreading of forest fires, and aircraft tracking. Machine learning can be utilized to analyze these mobility data to address global challenges, and Federated Learning (FL) is a promising approach because it eliminates the need for transmitting raw data and hence is both bandwidth and privacy-friendly. However, FL requires many communication rounds between clients (satellites) and the parameter server (PS), leading to substantial delays of up to several days in LEO constellations. In this paper, we propose a novel one-shot FL approach for LEO satellites, called LEOShot, that needs only a single communication round to complete the entire learning process. LEOShot comprises three processes: (i) synthetic data generation, (ii) knowledge distillation, and (iii) virtual model retraining. We evaluate and benchmark LEOShot against the state of the art and the results show that it drastically expedites FL convergence by more than an order of magnitude. Also surprisingly, despite the one-shot nature, its model accuracy is on par with or even outperforms regular iterative FL schemes by a large margin.},
  bibtex_show={true},
  abbr={MDM'23},
  preview={MDM.png},
  author={Elmahallawy, Mohamed and Luo, Tie},
  booktitle={2023 24th IEEE International Conference on Mobile Data Management (MDM)}, 
  title={One-Shot Federated Learning for LEO Constellations that Reduces Convergence Time from Days to 90 Minutes}, 
  year={2023},
  volume={},
  number={},
  pages={45-54},
  keywords={Space vehicles;Federated learning;Tracking;Low earth orbit satellites;Weather forecasting;Small satellites;Data models;Satellite communications;low Earth orbit (LEO);federated learning;knowledge distillation;ensemble model;synthetic data generation;teacher-student framework},
  doi={10.1109/MDM58254.2023.00020},
  pdf=MDM_PAPER.pdf,
  url={https://ieeexplore.ieee.org/abstract/document/10214895},
  html={https://ieeexplore.ieee.org/abstract/document/10214895}, 

  }

  @INPROCEEDINGS{10436841,
  abstract={Satellite technologies have advanced drastically in recent years, leading to a heated interest in launching small satellites into low Earth orbit (LEOs) to collect massive data such as satellite imagery. Downloading these data to a ground station (GS) to perform centralized learning to build an AI model is not practical due to the limited and expensive bandwidth. Federated learning (FL) offers a potential solution but will incur a very large convergence delay due to the highly sporadic and irregular connectivity between LEO satellites and GS. In addition, there are significant security and privacy risks where eavesdroppers or curious servers/satellites may infer raw data from satellites' model parameters transmitted over insecure communication channels. To address these issues, this paper proposes FedSecure, a secure FL approach designed for LEO constellations, which consists of two novel components: (1) decentralized key generation that protects satellite data privacy using a functional encryption scheme, and (2) on-orbit model forwarding and aggregation that generates a partial global model per orbit to minimize the idle waiting time for invisible satellites to enter the visible zone of the GS. Our analysis and results show that FedSecure preserves the privacy of each satellite's data against eavesdroppers, a curious server, or curious satellites. It is lightweight with significantly lower communication and computation overheads than other privacy-preserving FL aggregation approaches. It also reduces convergence delay drastically from days to only a few hours, yet achieving high accuracy of up to 85.35% using realistic satellite images.},
  bibtex_show={true},
  abbr={GLOBECOM'23},
  preview={GLOBECOM.png},
  author={Elmahallawy, Mohamed and Luo, Tie and Ibrahem, Mohamed I.},
  booktitle={GLOBECOM 2023 - 2023 IEEE Global Communications Conference}, 
  title={Secure and Efficient Federated Learning in LEO Constellations Using Decentralized Key Generation and On-Orbit Model Aggregation}, 
  year={2023},
  volume={},
  number={},
  pages={5727-5732},
  keywords={Data privacy;Satellites;Computational modeling;Low earth orbit satellites;Data models;Satellite images;Convergence;Low Earth orbit (LEO);satellite communication (SatCom);federated learning (FL);privacy preservation},
  doi={10.1109/GLOBECOM54140.2023.10436841},
  pdf=GLOBE_PAPER.pdf,
  url={https://ieeexplore.ieee.org/abstract/document/10436841},
  html={https://ieeexplore.ieee.org/abstract/document/10436841},
  selected={true} 
  }


@INPROCEEDINGS{10405810,
  abstract={Brain-Computer Interface (BCI) initially gained attention for developing applications that aid physically impaired individuals. Recently, the idea of integrating BCI with Augmented Reality (AR) emerged, which uses BCI not only to enhance the quality of life for individuals with disabilities but also to develop mainstream applications for healthy users. One commonly used BCI signal pattern is the Steady-state Visually-evoked Potential (SSVEP), which captures the brain's response to flickering visual stimuli. SSVEP-based BCI-AR applications enable users to express their needs/wants by simply looking at corresponding command options. However, individuals are different in brain signals and thus require per-subject SSVEP recognition. Moreover, muscle movements and eye blinks interfere with brain signals, and thus subjects are required to remain still during BCI experiments, which limits AR engagement. In this paper, we (1) propose a simple adaptive ensemble classification system that handles the inter-subject variability, (2) present a simple BCI-AR framework that supports the development of a wide range of SSVEP-based BCI-AR applications, and (3) evaluate the performance of our ensemble algorithm in an SSVEP-based BCI-AR application with head rotations which has demonstrated robustness to the movement interference. Our testing on multiple subjects achieved a mean accuracy of 80% on a PC and 77% using the HoloLens AR headset, both of which surpass previous studies that incorporate individual classifiers and head movements. In addition, our visual stimulation time is 5 seconds which is relatively short. The statistically significant results show that our ensemble classification approach outperforms individual classifiers in SSVEP-based BCIs.},
  bibtex_show={true},
  abbr={MetroXRAINE'23},
  preview={MetroXRAINE.png},
  author={Mustafa, Yasmine and Elmahallawy, Mohamed and Luo, Tie and Eldawlatly, Seif},
  booktitle={2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={A Brain-Computer Interface Augmented Reality Framework with Auto-Adaptive SSVEP Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={799-804},
  pdf=MetroXRAINE_PAPER.pdf,
  keywords={Visualization;Neural engineering;Brain-computer interfaces;Robustness;Steady-state;Augmented reality;Testing},
  doi={10.1109/MetroXRAINE58569.2023.10405810},
  url={https://ieeexplore.ieee.org/abstract/document/10405810},
  html={https://ieeexplore.ieee.org/abstract/document/10405810}, 
  }

